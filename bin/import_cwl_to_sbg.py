"""
Usage:
    import_cwl_to_cgc.py [options] (--cwl STR --token STR --project_id STR) [--cwl-inputs STR] \
                                    [--run-task --aws-instance-type STR]

Description:
    This tool will install a CWL workflow on one of
    the Seven Bridges platform (supported platforms Igor, CGC, Cavatica or GCP).
    Draft task will be created with the inputs described in cwl-inputs.
    Files are uploaded if they are not available in the project

Options:

    -h, --help                    Show this message.

    --cwl STR                     Standalone workflow in json format. Generated by "rabix -r" command.

    --cwl-inputs STR              Workflow inputs for creating a draft task and uploading input files.

    --token STR                   Developer token.

    --project_id STR              Project id (form project url: user-name/project-name)

    --run-task                    Run the draft task.

    --aws-instance-type STR       Set aws instance type for the execution.
                                  (More info http://www.ec2instances.info/; insert value from API NAME column)
"""


import sevenbridges as sbg
from sevenbridges.http.error_handlers import rate_limit_sleeper
from sevenbridges.http.error_handlers import maintenance_sleeper
from sevenbridges.http.error_handlers import general_error_sleeper
from docopt import docopt
import sys
from ruamel import yaml
from cwl_decomposer import breakdown_wf
import re
import os
from time import gmtime, strftime


def get_file_by_name(project_id, file_name, api):
    return api.files.query(limit=100, project=project_id, names=[file_name])[0].id


def process_inputs_json(inputs_path, project_id, api, raw_app):
    # Upload input files and modify inputs json to use input files

    def get_absolute_file_path(file_path, inputs_path1):
        # Get absolute file path from relative path and input json starting path
        input_dir = os.path.dirname(os.path.abspath(inputs_path1))
        while file_path.startswith('../'):
            file_path = file_path[3:]
            input_dir = '/'.join(input_dir.split('/')[0:-1])
        if file_path.startswith('./'):
            file_path = file_path[2:]
        return input_dir + '/' + file_path

    def get_filename_and_upload(path):
        # Upload a file to the platform
        file_name = path.split('/')[-1]
        if len(list(api.files.query(project=project_id, names=[file_name]))) == 0:
            sys.stderr.write('Uploading: %s. Please wait...\n' % file_name)
            api.files.upload(project=project_id, path=get_absolute_file_path(path, inputs_path))
        else:
            sys.stderr.write('File %s already exists. Using existing file.\n' % file_name)
        return file_name

    def get_secondary_file_path(primary_path, secondary_string):
        # Get secondary file name from secondary string
        secondary_path = primary_path
        while secondary_string.startswith('^'):
            secondary_string = secondary_string[1:]
            secondary_path = '.'.join(secondary_path.split('.')[:-1])
        secondary_path += secondary_string
        return secondary_path

    # Load inputs json
    with open(inputs_path) as f:
        inputs = f.read()
    inputs = yaml.safe_load(inputs)

    def process_input(input_id, input_object, inputs_json, sec_strings):
        """Recursive iteration through an input to upload files and replace paths with SBG ID"""
        if isinstance(input_object, list):  # list of items
            for i, elem in enumerate(input_object):
                process_input(i, elem, input_object, sec_strings)
        elif isinstance(input_object, dict):
            if input_object["class"].lower() == "file":
                # Find input file path
                input_file_path = input_object["path"] if "path" in input_object else input_object["location"]

                # Get basename and upload file to the platform
                filename = get_filename_and_upload(input_file_path)

                # Upload secondary files to the platform
                for sec in sec_file_strings:
                    get_filename_and_upload(get_secondary_file_path(input_file_path, sec))

                # Replace local path with SBG file id in the inputs json
                inputs_json[input_id]["path"] = get_file_by_name(project_id, filename, api)
                # Clear location and secondaryFiles fields from inputs json
                inputs_json[input_id].pop("location", None)
                inputs_json[input_id].pop("secondaryFiles", None)
            # TODO cover Dictionary and Record

        return inputs_json

    # Iterate through inputs
    for in_id, inp in inputs.items():
        # Check for secondary files
        if isinstance(raw_app['inputs'], list):
            raw_app_inp = [raw_app['inputs'][i] for i in range(len(raw_app['inputs']))
                           if raw_app['inputs'][i]['id'] == in_id][0]
            sec_file_strings = raw_app_inp['secondaryFiles'] if 'secondaryFiles' in raw_app_inp else []
        else:
            sec_file_strings = raw_app['inputs'][in_id]['secondaryFiles'] \
                if 'secondaryFiles' in raw_app['inputs'][in_id] else []

        inputs = process_input(in_id, inp, inputs, sec_file_strings)

    return inputs


def init_api(dev_token):
    """Initialize api for the platform used"""
    platforms = {'igor': "https://api.sbgenomics.com/v2",
                 'cgc': "https://cgc-api.sbgenomics.com/v2",
                 'cavatica': "https://cavatica-api.sbgenomics.com/v2"}
    for p in platforms:
        try:
            api = sbg.Api(url=platforms[p], token=dev_token,
                      error_handlers=[rate_limit_sleeper, maintenance_sleeper, general_error_sleeper])
            api.users.me()
            break
        except:
            continue
    else:
        raise ValueError('Invalid token')
    return api


def replace_special_characters(string):
    return '-'.join([
                 x for x in filter(lambda x: x != '',
                                   re.sub('[^a-zA-Z0-9]', ' ', str(string).lower()).split(' '))])


def install_or_upgrade_app(step_id, project_id, raw_json, api):
    """Update the app if it exists, install it if not"""
    # Replace special characters in step id with -
    step_id = replace_special_characters(step_id)
    # Check if app exists in the project
    if len([a for a in api.apps.query(project=project_id).all() if a.id == '{}/{}'.format(project_id, step_id)]) == 1:
        existing_app = api.apps.get(api=api, id='{}/{}'.format(project_id, step_id))
        updated_app = existing_app.create_revision(id=existing_app.id, revision=existing_app.revision+1,
                                                   raw=raw_json)
    else:  # install the app if it does not exist
        updated_app = api.apps.install_app(id='{}/{}'.format(project_id, step_id), raw=raw_json)
    return updated_app


def main():

    # region Docopt interface
    args = docopt(__doc__, version='1.0')

    wf_json_path = args['--cwl']
    cwl_inputs_path = args['--cwl-inputs']
    project_id = args['--project_id']
    dev_token = args['--token']
    run_task = args['--run-task']
    aws_instance = args['--aws-instance-type']

    api = init_api(dev_token)
    # endregion

    # region Installing workflow
    # Load raw json standalone workflow
    with open(wf_json_path, 'rb') as f:
        raw_app = f.read()
    raw_app = yaml.safe_load(raw_app)

    # Set instance type if it is set on input
    if aws_instance:
        if 'hints' not in raw_app:
            raw_app['hints'] = list()
        raw_app['hints'].append({"class": "sbg:AWSInstanceType", "value": aws_instance})

    # Get app name and id from input name
    wf_json_name = wf_json_path.split('/')[-1]
    app_name = '_'.join(wf_json_name.split('.')[:-1]).lower()

    # Install or upgrade the app
    installed_wf = install_or_upgrade_app(app_name + '_imported', project_id, raw_app, api)

    workflow = breakdown_wf(installed_wf.id.split('/')[2], project_id, installed_wf.raw, api)
    sys.stderr.write('Workflow %s installed\n' % workflow.id)
    # endregion

    # Restructure inputs json, upload files and run the task
    if cwl_inputs_path:
        task_inputs = process_inputs_json(cwl_inputs_path, project_id, api, raw_app)

        # Create a draft task
        task_name = app_name + ' - ' + strftime("%Y-%m-%d %H:%M:%S", gmtime())
        template_task = api.tasks.create(name=task_name, project=project_id,
                                         app=workflow.id, inputs=task_inputs)

        # Check for errors
        task_err = template_task.errors
        if len(task_err) > 0:
            sys.stderr.write('Task errors: \n')
            sys.stderr.write(str(task_err) + '\n')
        else:
            sys.stderr.write("Draft task created. No errors.\n")
            if run_task:
                template_task.run()
                sys.stderr.write("Task started!\n")
    # endregion


if __name__ == '__main__':
    sys.exit(main())
